{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1480c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjet/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from scipy.sparse import save_npz\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4fd9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded preprocessed data: (545, 20)\n",
      "Sample cleaned_text: ['account sign ksh hourly nairobi reply stop unsubscribe', 'congratulation account credit kes new bonus balance kes login deposit play']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/preprocessed_scam_data.pkl')\n",
    "print('Loaded preprocessed data:', df.shape)\n",
    "print('Sample cleaned_text:', df['cleaned_text'].iloc[:2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96706057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (545, 3447)\n",
      "Sample TF-IDF features: ['abroad' 'academic' 'acc' 'acc past' 'acc past yrs' 'acc secret'\n",
      " 'acc secret pin' 'accept' 'accept deadline' 'accept deadline september']\n"
     ]
    }
   ],
   "source": [
    "# 1. TF-IDF Vectorization\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 3), min_df=2)\n",
    "\n",
    "\n",
    "texts = df['cleaned_text'].fillna('').str.strip()\n",
    "\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "\n",
    "save_npz('tfidf_matrix.npz', tfidf_matrix)\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "print('TF-IDF matrix shape:', tfidf_matrix.shape)\n",
    "print('Sample TF-IDF features:', tfidf_vectorizer.get_feature_names_out()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/sentence-transformers/paraphrase-mpnet-base-v2/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://huggingface.co/sentence-transformers/paraphrase-mpnet-base-v2/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "sentence-transformers/paraphrase-mpnet-base-v2 does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 2. Sentence-BERT Embeddings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sbert_model = \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mparaphrase-mpnet-base-v2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m batch_size = \u001b[32m32\u001b[39m\n\u001b[32m      7\u001b[39m texts = df[\u001b[33m'\u001b[39m\u001b[33mcleaned_text\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m).str.strip().tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:309\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    300\u001b[39m         model_name_or_path = __MODEL_HUB_ORGANIZATION__ + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m + model_name_or_path\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[32m    303\u001b[39m     model_name_or_path,\n\u001b[32m    304\u001b[39m     token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m     local_files_only=local_files_only,\n\u001b[32m    308\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    321\u001b[39m     modules = \u001b[38;5;28mself\u001b[39m._load_auto_model(\n\u001b[32m    322\u001b[39m         model_name_or_path,\n\u001b[32m    323\u001b[39m         token=token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m         config_kwargs=config_kwargs,\n\u001b[32m    331\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1808\u001b[39m, in \u001b[36mSentenceTransformer._load_sbert_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[39m\n\u001b[32m   1805\u001b[39m \u001b[38;5;66;03m# Try to initialize the module with a lot of kwargs, but only if the module supports them\u001b[39;00m\n\u001b[32m   1806\u001b[39m \u001b[38;5;66;03m# Otherwise we fall back to the load method\u001b[39;00m\n\u001b[32m   1807\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1808\u001b[39m     module = \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1809\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1810\u001b[39m     module = module_class.load(model_name_or_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:81\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[39m\n\u001b[32m     78\u001b[39m     config_args = {}\n\u001b[32m     80\u001b[39m config, is_peft_model = \u001b[38;5;28mself\u001b[39m._load_config(model_name_or_path, cache_dir, backend, config_args)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_peft_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n\u001b[32m     84\u001b[39m     tokenizer_args[\u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m] = max_seq_length\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:181\u001b[39m, in \u001b[36mTransformer._load_model\u001b[39m\u001b[34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[39m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mself\u001b[39m._load_mt5_model(model_name_or_path, config, cache_dir, **model_args)\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28mself\u001b[39m.auto_model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_peft_model:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28mself\u001b[39m._load_peft_model(model_name_or_path, config, cache_dir, **model_args, **adapter_only_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:279\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    281\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4260\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4251\u001b[39m     gguf_file\n\u001b[32m   4252\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4253\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4254\u001b[39m ):\n\u001b[32m   4255\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4256\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4260\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4262\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4267\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4273\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4275\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4276\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4278\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4279\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1080\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash)\u001b[39m\n\u001b[32m   1072\u001b[39m has_file_kwargs = {\n\u001b[32m   1073\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrevision\u001b[39m\u001b[33m\"\u001b[39m: revision,\n\u001b[32m   1074\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproxies\u001b[39m\u001b[33m\"\u001b[39m: proxies,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1077\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlocal_files_only\u001b[39m\u001b[33m\"\u001b[39m: local_files_only,\n\u001b[32m   1078\u001b[39m }\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_file(pretrained_model_name_or_path, TF2_WEIGHTS_NAME, **has_file_kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1080\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m   1081\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not appear to have a file named\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1082\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but there is a file for TensorFlow weights.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1083\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Use `from_tf=True` to load this model from those weights.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1084\u001b[39m     )\n\u001b[32m   1085\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m has_file(pretrained_model_name_or_path, FLAX_WEIGHTS_NAME, **has_file_kwargs):\n\u001b[32m   1086\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m   1087\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not appear to have a file named\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1088\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but there is a file for Flax weights. Use\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1089\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m `from_flax=True` to load this model from those weights.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1090\u001b[39m     )\n",
      "\u001b[31mOSError\u001b[39m: sentence-transformers/paraphrase-mpnet-base-v2 does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights."
     ]
    }
   ],
   "source": [
    "# 2. Sentence-BERT Embeddings\n",
    "\n",
    "sbert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "texts = df['cleaned_text'].fillna('').str.strip().tolist()\n",
    "sbert_embeddings = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i + batch_size]\n",
    "    batch_texts = [text if text else 'placeholder' for text in batch_texts]\n",
    "    embeddings = sbert_model.encode(batch_texts, show_progress_bar=(i == 0))\n",
    "    sbert_embeddings.append(embeddings)\n",
    "\n",
    "sbert_embeddings = np.vstack(sbert_embeddings)\n",
    "np.save('sbert_embeddings.npy', sbert_embeddings)\n",
    "print('Sentence-BERT embeddings shape:', sbert_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "264836d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
      " (5.96%) [==>                                                ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]>                                                  ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]                                                 ]>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]                                                 ]>                                                 ]=>                                                 ]]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]                                                 ]=>                                                 ]                                                 ]                                                 ]                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]=>                                                 ]]                                                 ]                                                 ]=>                                                 ]                                                 ]]==>                                                ]==>                                                ]==>                                                ]==>                                                ]                                                ]>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]                                                ]]==>                                                ]==>                                                ]==>                                                ]==>                                                ]                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]>                                                ]==>                                                ]==>                                                ]]>                                                ]]==>                                                ]>                                                ]                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]]==>                                                ]]==>                                                ]==>                                                ]]==>                                                ]==>                                                ]==>                                                ]]==>                                                ]]                                                ]                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]]==>                                                ]==>                                                ]==>                                                ]]]==>                                                ]                                                ]]>                                                ]>                                                ]]                                                ]                                                ]                                                ]]==>                                                ]==>                                                ]                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]==>                                                ]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 3. FastText Word Embeddings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43men\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m ft_model = fasttext.load_model(\u001b[33m'\u001b[39m\u001b[33mcc.en.300.bin\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_fasttext_embedding\u001b[39m(text, model, dim=\u001b[32m300\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/fasttext/util/util.py:204\u001b[39m, in \u001b[36mdownload_model\u001b[39m\u001b[34m(lang_id, if_exists, dimension)\u001b[39m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m if_exists == \u001b[33m'\u001b[39m\u001b[33moverwrite\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    202\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_download_gz_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgz_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m gzip.open(gz_file_name, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    206\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_name, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_out:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/fasttext/util/util.py:178\u001b[39m, in \u001b[36m_download_gz_model\u001b[39m\u001b[34m(gz_file_name, if_exists)\u001b[39m\n\u001b[32m    175\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    177\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://dl.fbaipublicfiles.com/fasttext/vectors-crawl/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % gz_file_name\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[43m_download_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgz_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iwazolab/NLP-Scam-Detection/.venv/lib/python3.12/site-packages/fasttext/util/util.py:157\u001b[39m, in \u001b[36m_download_file\u001b[39m\u001b[34m(url, write_file_name, chunk_size)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(download_file_name, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         chunk = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         downloaded += \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 3. FastText Word Embeddings\n",
    "\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "ft_model = fasttext.load_model('cc.en.300.bin')\n",
    "\n",
    "\n",
    "def get_fasttext_embedding(text, model, dim=300):\n",
    "    if not text or text.isspace():\n",
    "        return np.zeros(dim)\n",
    "    words = text.split()\n",
    "    vectors = [model.get_word_vector(word) for word in words if word in model]\n",
    "    if not vectors:\n",
    "        return np.zeros(dim)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "fasttext_embeddings = np.array([\n",
    "    get_fasttext_embedding(text, ft_model) for text in texts\n",
    "])\n",
    "\n",
    "\n",
    "np.save('fasttext_embeddings.npy', fasttext_embeddings)\n",
    "\n",
    "print('FastText embeddings shape:', fasttext_embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
